{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceThreeOrMore(text):\n",
    "    \n",
    "    \"\"\"\n",
    "    look for 3 or more repetitions of character (and newline) and replace with the character itself\n",
    "    eg: 'hahahah' --- 'hahah'\n",
    "        'rougeee' --- 'rougee'\n",
    "        '😊😊😊'   --- '😊😊'\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    pattern = re.compile(r\"(.+)\\1{2,}\", re.DOTALL)\n",
    "    return pattern.sub(r\"\\1\\1\", text)\n",
    "\n",
    "\n",
    "#text = \"agcddd u'\\U0001f6bb'u'\\U0001f6bb'u'\\U0001f6bb' hahaha www:'http: \" \n",
    "#print (replaceThreeOrMore(text))\n",
    "\n",
    "\n",
    "def replace_non_alphanumeric_begin_sentence(text):\n",
    "    \"\"\"\n",
    "    replace any text that begins with non [a-zA-Z0-9] character with its\n",
    "    original\n",
    "    eg: '###abc asd' ---> 'abc asd'\n",
    "        '.abc efg ---> abc efg'\n",
    "    \"\"\"\n",
    "    return re.sub(r\"^[^A-Za-z0-9]+(.*)\", r\"\\1\", text)\n",
    "\n",
    "\n",
    "#print (replace_non_alphanumeric_begin_sentence(\"...abc paris \"))\n",
    "\n",
    "def replace_url_by(text, entity = 'URL'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Convert www.* or https?://* to URL and return a 2-elements tuple.\n",
    "    \n",
    "    Eg: \n",
    "    >> text = \"les liens sont: http://abc.com et www.hotmail.com\"\n",
    "    >> replace_url_by(text)\n",
    "    >> ('les liens sont: URL et URL', [('http://abc.com', 'URL'), ('www.hotmail.com', 'URL')])\n",
    "\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    all_url = re.findall(r'((www[]*\\.[]*[^\\s]+)|(http[s ]*(?:[/\\.]*)[^\\s]*))', text)\n",
    "    url_tuple = [(url[0], entity) for url in all_url]\n",
    "    \n",
    "    \n",
    "    return (re.sub(r'((www[]*\\.[]*[^\\s]+)|(http[s ]*(?:[/\\.]*)[^\\s]*))', entity, text), url_tuple)\n",
    "\n",
    "\n",
    "\n",
    "def replace_email_by(text, entity = 'EMAIL'):\n",
    "    \"\"\"\n",
    "    Convert email abc@disney.com to EMAIL and return a 2-elements tuple.\n",
    "    \n",
    "    Eg: \n",
    "    >> text = \"Ton email est: abc@gmail.com et son email est: efg@hotmail.com\"\n",
    "    >> replace_email_by(text)\n",
    "    >> ('Ton email est: EMAIL et son email est: EMAIL',[('abc@gmail.com', 'EMAIL'), ('efg@hotmail.com', 'EMAIL')])\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    all_emails = re.findall(r\"([a-zA-Z0-9_.+-]+(@|\\[at\\]|\\(at\\))[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)\", text)\n",
    "    email_tuple = [(eml[0], entity) for eml in all_emails] \n",
    "    \n",
    "    return (re.sub(r\"([a-zA-Z0-9_.+-]+(@|\\[at\\]|\\(at\\))[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)\", entity, text), email_tuple)\n",
    "\n",
    "#print (replace_email_by(\"Mon email addresse est:  abc@disneyland.fr\")) \n",
    "\n",
    "\n",
    "\n",
    "def replace_emoji_by(text, entity = 'EMOJI'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Convert emoji 😊 to EMOJI and return a 2-elements tuple.\n",
    "    \n",
    "    Eg: \n",
    "    >> text = \"Merci 😊👍\"\n",
    "    >> replace_emoji_by(text)\n",
    "    >> ('Merci EMOJIEMOJI', [('😊', 'EMOJI'), ('👍', 'EMOJI')])\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    emojis = [(char, entity) for char in casual_tokenize(text) if char in list(emoji.UNICODE_EMOJI.keys())]\n",
    "    return (u''.join(entity if char in list(emoji.UNICODE_EMOJI.keys()) else char for char in text), emojis)\n",
    "\n",
    "    \n",
    "#print (replace_emoji_by(\"Merci 😊👍\", entity = 'EMOJI'))\n",
    "\n",
    "\n",
    "\n",
    "def add_space_to_punct(text):\n",
    "    for char in ['.', '\"', ',', '(', ')', '!', '?', ';', ':']:\n",
    "        text = text.replace(char, ' ' + char + ' ')\n",
    "    return text\n",
    "    \n",
    "    \n",
    "    \n",
    "def replace_voyelle_with_accent(text):\n",
    "        voyelle_dic = {'à' : 'a',\n",
    "                       'â' : 'a',\n",
    "                       'é' : 'e', \n",
    "                       'è' : 'e', \n",
    "                       'ê' : 'e', \n",
    "                       'ë' : 'e', \n",
    "                       'ù' : 'u', \n",
    "                       'ô' : 'o',\n",
    "                       'û' : 'u'}\n",
    "        \n",
    "        for v in voyelle_dic.keys():\n",
    "            text = text.replace(v, voyelle_dic[v])\n",
    "        return text\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    \n",
    "    text = replace_non_alphanumeric_begin_sentence(text)\n",
    "    text = replace_url_by(text)[0]   ##replace_url_by should be before replaceThreeOrMore otherwise www. ---> ww.\\n\",\n",
    "    text = replace_email_by(text)[0]\n",
    "    text = replaceThreeOrMore(text)  ## put this one at the end since www.abc.com\\n\",\n",
    "    #text = replace_voyelle_with_accent(text)\n",
    "    text = add_space_to_punct(text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def get_ith_turn_index(df, ith, agent = 0):\n",
    "    \n",
    "    if agent == 0:\n",
    "        grouped_df = df[df['agent'] == 'visitor'].groupby(['conv_uid'])\n",
    "    elif agent == 1:\n",
    "        grouped_df = df[df['agent'] == 'operator'].groupby(['conv_uid'])\n",
    "    elif agent == 2:\n",
    "        grouped_df = df.groupby(['conv_uid'])\n",
    "    else:\n",
    "        print ('agent value not valid')\n",
    "    \n",
    "    turns = []\n",
    "    \n",
    "    for i in grouped_df.groups.keys():\n",
    "        try:\n",
    "            messages = grouped_df.get_group(i)\n",
    "            if len(messages) >= ith:\n",
    "                turns.append(messages.iloc[[ith-1]].index.values[0])\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return turns\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "def symmetric_KL_distance(p, q):\n",
    "    p = p + 10**(-8)\n",
    "    q = q + 10**(-8)\n",
    "    avg = (p+q)/2\n",
    "    return 0.5*(stats.entropy(p, avg) + stats.entropy(q, avg))\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "def transformText(text, stops):\n",
    "    \n",
    "    #stops = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    # Convert text to lower\n",
    "    text = text.lower()\n",
    "    # Removing non ASCII chars    \n",
    "    #text = re.sub(r'[^\\x00-\\x7f]',r' ',text)\n",
    "    \n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    \n",
    "    # Removing all the stopwords\n",
    "    filtered_words = [word for word in text.split() if word not in stops]\n",
    "    \n",
    "    # Removing all the tokens with lesser than 2 characters\n",
    "    filtered_words = gensim.corpora.textcorpus.remove_short(filtered_words, minsize=2)\n",
    "    \n",
    "    # Preprocessed text after stop words removal\n",
    "    text = \" \".join(filtered_words)\n",
    "    \n",
    "    # Remove the punctuation\n",
    "    text = gensim.parsing.preprocessing.strip_punctuation2(text)\n",
    "    \n",
    "    # Strip all the numerics\n",
    "    #text = gensim.parsing.preprocessing.strip_numeric(text)\n",
    "    \n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    \n",
    "    # Stemming\n",
    "    #return gensim.parsing.preprocessing.stem_text(text)\n",
    "    return text\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
